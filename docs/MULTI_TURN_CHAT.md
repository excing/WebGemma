# 多轮对话功能实现

## 🎯 功能概述

Gemma AI 助手现在支持完整的多轮对话功能，AI 能够记住之前的对话内容，提供更连贯和智能的回复。

## ✨ 核心特性

### 1. 聊天上下文记忆
- **自动记忆**：AI 自动记住最近的对话历史
- **智能上下文**：将历史对话作为上下文传递给模型
- **连贯回复**：基于对话历史提供更相关的回复

### 2. 可配置的上下文长度
- **灵活设置**：支持 1-50 轮对话的上下文长度
- **性能平衡**：可根据需要调整记忆长度
- **实时调整**：无需重启即可修改设置

### 3. 上下文管理
- **启用/禁用**：可以随时开关上下文记忆功能
- **历史清除**：支持清除聊天历史重新开始
- **状态显示**：实时显示当前上下文状态

### 4. 多模态上下文支持
- **文本记忆**：记住文本对话内容
- **多媒体支持**：支持图片和音频的上下文传递
- **混合对话**：文本、图片、音频混合对话的完整支持

## 🛠️ 技术实现

### 1. AIService 增强
```typescript
// 聊天历史管理
private chatHistory: Message[] = [];
private maxContextLength = 10;

// 构建上下文提示
private buildContextPrompt(text: string): string {
  // 添加历史对话到提示中
  // 格式：User: xxx\nAssistant: xxx\n...
}

// 更新聊天历史
private updateChatHistory(userMessage: Message, assistantResponse: string): void {
  // 添加用户消息和AI回复到历史中
  // 自动限制历史长度
}
```

### 2. ChatStore 扩展
```typescript
// 新增状态
interface ChatState {
  contextLength: number;    // 上下文长度
  enableContext: boolean;   // 是否启用上下文
  // ... 其他状态
}

// 新增方法
setContextLength(length: number): void;
toggleContext(): void;
clearChatHistory(): void;
getChatHistory(): Message[];
```

### 3. 上下文设置组件
- **ChatContextSettings.svelte**：专用的上下文设置界面
- **直观控制**：滑块调节、开关切换、状态显示
- **实时反馈**：显示当前设置和消息统计

## 🎮 使用方法

### 基础使用
1. **启动对话**：正常发送消息，AI 会自动记住对话
2. **连续对话**：后续消息会基于之前的对话内容回复
3. **查看状态**：点击聊天气泡图标查看上下文设置

### 上下文设置
1. **打开设置**：点击界面右上角的聊天气泡图标
2. **调整长度**：拖动滑块设置记忆的对话轮数
3. **开关记忆**：使用切换按钮启用/禁用上下文记忆
4. **清除历史**：点击"清除聊天历史"重新开始

### 最佳实践
- **日常对话**：使用 5-10 轮上下文，平衡性能和连贯性
- **复杂任务**：使用 15-25 轮上下文，保持长期记忆
- **性能优先**：禁用上下文或使用 1-3 轮，获得最快响应
- **隐私保护**：定期清除历史，保护对话隐私

## 📊 性能影响

### 上下文长度对性能的影响
| 上下文长度 | 响应速度 | 内存占用 | 推荐场景 |
|------------|----------|----------|----------|
| 1-5 轮     | 快       | 低       | 简单问答 |
| 6-15 轮    | 中等     | 中等     | 日常对话 |
| 16-30 轮   | 较慢     | 较高     | 复杂任务 |
| 31-50 轮   | 慢       | 高       | 长期项目 |

### 优化建议
1. **根据任务调整**：简单问答使用短上下文，复杂任务使用长上下文
2. **定期清理**：完成一个话题后清除历史，开始新话题
3. **监控性能**：如果响应变慢，适当减少上下文长度
4. **合理使用**：不是所有对话都需要长上下文

## 🔧 配置选项

### 默认设置
```typescript
const defaultSettings = {
  contextLength: 10,        // 默认记忆 10 轮对话
  enableContext: true,      // 默认启用上下文
  maxContextLength: 50      // 最大支持 50 轮
};
```

### 可调整参数
- **上下文长度**：1-50 轮（推荐 5-15 轮）
- **启用状态**：开启/关闭上下文记忆
- **历史管理**：清除历史、查看状态

## 🎯 使用场景

### 1. 学习辅导
```
用户：什么是机器学习？
AI：机器学习是人工智能的一个分支...

用户：它有哪些类型？
AI：基于我刚才介绍的机器学习，主要有三种类型...
```

### 2. 代码开发
```
用户：帮我写一个 Python 函数计算斐波那契数列
AI：好的，我来为你写一个斐波那契函数...

用户：能优化一下性能吗？
AI：当然可以，基于刚才的函数，我们可以使用动态规划...
```

### 3. 创意写作
```
用户：帮我写一个科幻故事的开头
AI：在2157年的地球上...

用户：继续这个故事，加入一些悬疑元素
AI：接着刚才的故事，主角发现了一个神秘的信号...
```

## 🔍 故障排除

### 常见问题

**Q: AI 没有记住之前的对话**
A: 检查上下文设置是否启用，确认上下文长度大于 0

**Q: 响应速度变慢**
A: 减少上下文长度或清除聊天历史

**Q: 上下文设置不生效**
A: 刷新页面或重新加载模型

**Q: 内存占用过高**
A: 减少上下文长度，定期清除历史

### 调试方法
1. **检查设置**：确认上下文设置正确
2. **查看历史**：检查聊天历史是否正常记录
3. **测试连续性**：发送相关问题测试AI是否记住上下文
4. **性能监控**：观察响应时间和内存使用

## 🚀 未来改进

### 计划中的功能
1. **智能上下文**：自动判断最相关的历史对话
2. **主题分组**：按对话主题自动分组管理
3. **导出历史**：支持导出聊天记录
4. **云端同步**：跨设备同步聊天历史

### 性能优化
1. **压缩算法**：优化上下文存储和传输
2. **缓存机制**：缓存常用的上下文模式
3. **异步处理**：后台处理上下文构建
4. **智能截断**：保留最重要的对话内容

多轮对话功能让 Gemma AI 助手更加智能和实用，能够进行真正的连续对话，为用户提供更好的交互体验。
